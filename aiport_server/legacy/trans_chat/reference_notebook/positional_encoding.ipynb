{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Positional Encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 요약\n",
    "\n",
    "### 구현 코드"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, LongTensor\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout=0.1, max_len = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)    # 0부터 2칸씩\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)    # 1부터 2칸씩\n",
    "        self.pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "    \n",
    "    def forward(self, x: Tensor):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "source": [
    "### 실행 결과"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 0.2425,  2.3717, -0.7872,  ...,  1.5883, -1.1851,  3.2972],\n",
       "         [ 0.7976,  0.9716, -1.0545,  ...,  2.5640, -1.1092,  1.8013],\n",
       "         [ 1.3725,  0.0000,  0.8368,  ...,  0.0000, -0.6474,  0.8655],\n",
       "         ...,\n",
       "         [-0.6386,  0.2735, -2.2655,  ...,  2.1753, -1.2832,  0.0000],\n",
       "         [-0.6386,  0.2735, -2.2655,  ...,  2.1753, -1.2832,  0.0000],\n",
       "         [-0.6386,  0.2735, -2.2655,  ...,  0.0000, -1.2832,  0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "input_embedding = nn.Embedding(4376, 512)\n",
    "pos_encoding = PositionalEncoding(512)\n",
    "\n",
    "# 임베딩 입력은 무조건 정수로 받는다\n",
    "input_tensor = LongTensor([[2, 1819, 1547, 1698, 230, 3869, 2661, 3596, 3744, 1341, 3155, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "embedded_tensor = input_embedding(input_tensor)\n",
    "\n",
    "pos_encoding(embedded_tensor)"
   ]
  },
  {
   "source": [
    "# 수행 과정"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 5\n",
    "d_model = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "pe = torch.zeros(max_len, d_model)\n",
    "print(pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.],\n        [1.],\n        [2.],\n        [3.],\n        [4.]])\n"
     ]
    }
   ],
   "source": [
    "position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1.0000e+00, 1.0000e-01, 1.0000e-02, 1.0000e-03])\n"
     ]
    }
   ],
   "source": [
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "print(div_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n          1.0000e+00,  0.0000e+00,  1.0000e+00],\n        [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n          9.9995e-01,  1.0000e-03,  1.0000e+00],\n        [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n          9.9980e-01,  2.0000e-03,  1.0000e+00],\n        [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n          9.9955e-01,  3.0000e-03,  1.0000e+00],\n        [-7.5680e-01, -6.5364e-01,  3.8942e-01,  9.2106e-01,  3.9989e-02,\n          9.9920e-01,  4.0000e-03,  9.9999e-01]])\n"
     ]
    }
   ],
   "source": [
    "pe[:, 0::2] = torch.sin(position * div_term)    # 0부터 2칸씩\n",
    "pe[:, 1::2] = torch.cos(position * div_term)    # 1부터 2칸씩\n",
    "\n",
    "print(pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           1.0000e+00,  0.0000e+00,  1.0000e+00],\n         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n           9.9995e-01,  1.0000e-03,  1.0000e+00],\n         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n           9.9980e-01,  2.0000e-03,  1.0000e+00],\n         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n           9.9955e-01,  3.0000e-03,  1.0000e+00],\n         [-7.5680e-01, -6.5364e-01,  3.8942e-01,  9.2106e-01,  3.9989e-02,\n           9.9920e-01,  4.0000e-03,  9.9999e-01]]])\n\ntensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           1.0000e+00,  0.0000e+00,  1.0000e+00]],\n\n        [[ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n           9.9995e-01,  1.0000e-03,  1.0000e+00]],\n\n        [[ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n           9.9980e-01,  2.0000e-03,  1.0000e+00]],\n\n        [[ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n           9.9955e-01,  3.0000e-03,  1.0000e+00]],\n\n        [[-7.5680e-01, -6.5364e-01,  3.8942e-01,  9.2106e-01,  3.9989e-02,\n           9.9920e-01,  4.0000e-03,  9.9999e-01]]])\n"
     ]
    }
   ],
   "source": [
    "pe = pe.unsqueeze(0)\n",
    "print(pe)\n",
    "print()\n",
    "pe = pe.transpose(0, 1)\n",
    "\n",
    "print(pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}